{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybridbrep import HybridPart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import meshplot as mp\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part = HybridPart('../../datasets/cubes/angled_cube.x_t', 500, 5000, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automate import HetData\n",
    "from hybridbrep_cpp import HybridPart\n",
    "from math import ceil, sqrt\n",
    "import torch\n",
    "import numpy as np\n",
    "class HPart():\n",
    "    def __init__(self, path, n_samples=500, n_ref_samples=5000, normalize=False):\n",
    "        part = HybridPart(path, n_samples, n_ref_samples, normalize)\n",
    "        data = HetData()\n",
    "        ### Part Level Stats ###\n",
    "        data.bounding_box = torch.tensor(part.bounding_box.reshape((1,2,3))).float()\n",
    "        data.translation = torch.tensor(part.translation).float()\n",
    "        data.scale = torch.tensor(part.scale).float()\n",
    "        data.__node_sets__.add('bounding_box')\n",
    "        data.__node_sets__.add('translation')\n",
    "        data.__node_sets__.add('scale')\n",
    "        \n",
    "        ### Face Encodings ###\n",
    "        # One-Hot Encode Surface Types -- Non-Simple are all 0s\n",
    "        face_surfaces = torch.tensor(part.face_surfaces, dtype=int)\n",
    "        face_surfaces = torch.nn.functional.one_hot(face_surfaces, max(5, face_surfaces.max())).float()\n",
    "        face_surfaces = face_surfaces[:,:5]\n",
    "        face_surface_parameters = torch.tensor(part.face_surface_parameters).float()\n",
    "        face_surface_flipped = torch.tensor(part.face_surface_flipped).reshape((-1,1)).float()\n",
    "        data.faces = torch.cat([face_surfaces, face_surface_parameters, face_surface_flipped],dim=1).float()\n",
    "        data.__node_sets__.add('faces')\n",
    "\n",
    "        ### Edge Encodings ###\n",
    "        # One-Hot Encode Curve Types -- Nno-Simple are all 0s\n",
    "        edge_curves = torch.tensor(part.edge_curves, dtype=int)\n",
    "        edge_curves = torch.nn.functional.one_hot(edge_curves, max(3, edge_curves.max())).float()\n",
    "        edge_curves = edge_curves[:,:3]\n",
    "        edge_curve_parameters = torch.tensor(part.edge_curve_parameters).float()\n",
    "        edge_curve_flipped = torch.tensor(part.edge_curve_flipped).reshape((-1,1)).float()\n",
    "        data.edges = torch.cat([edge_curves, edge_curve_parameters, edge_curve_flipped],dim=1).float()\n",
    "        data.__node_sets__.add('edges')\n",
    "\n",
    "        ### Vertex Encodings ###\n",
    "        data.vertices = torch.tensor(part.vertex_positions).float()\n",
    "        data.__node_sets__.add('vertices')\n",
    "\n",
    "        ### Relationships ###\n",
    "        data.face_to_face = torch.tensor(part.face_to_face).long()\n",
    "        data.edge_to_face = torch.tensor([part.face_to_edge[1], part.face_to_edge[0]]).long()\n",
    "        data.edge_to_face_flipped = torch.tensor(part.face_to_edge_flipped).reshape((-1,1)).float()\n",
    "        data.vertex_to_edge = torch.tensor([part.edge_to_vertex[1], part.edge_to_vertex[0]]).long()\n",
    "        data.vertex_to_edge_is_start = torch.tensor(part.edge_to_vertex_is_start).reshape((-1,1)).float()\n",
    "        data.__edge_sets__['face_to_face'] = ['faces', 'faces', 'edges']\n",
    "        data.__edge_sets__['edge_to_face'] = ['edges', 'faces']\n",
    "        data.__edge_sets__['vertex_to_edge'] = ['vertices', 'edges']\n",
    "        data.__node_sets__.add('edge_to_face_flipped')\n",
    "        data.__node_sets__.add('vertex_to_edge_is_start')\n",
    "\n",
    "\n",
    "        ### Surface and Curve Samples ###\n",
    "        curve_size = int(ceil(sqrt(n_samples)))\n",
    "\n",
    "        data.surface_bounds = torch.tensor(np.stack(part.surface_bounds)).float() if len(part.surface_bounds) > 0 else torch.empty((0,2,2))\n",
    "        data.surface_coords = torch.tensor(np.stack(part.surface_coords)).float() if len(part.surface_coords) > 0 else torch.empty((0,n_samples,2))\n",
    "        \n",
    "        data.surface_samples = torch.tensor(np.stack(part.surface_samples)).float() if len(part.surface_samples) > 0 else torch.empty((0,n_samples,7))\n",
    "        data.curve_bounds = torch.tensor(np.stack(part.curve_bounds)).float() if len(part.curve_bounds) > 0 else torch.empty((0, 2)).float()\n",
    "        data.curve_samples = torch.tensor(np.stack(part.curve_samples)).float() if len(part.curve_samples) > 0 else torch.empty((0,curve_size,6)).float()\n",
    "        # Flip the curve samples to make edge samples\n",
    "        # Masks and sums flipped and unflipped versions of every edge\n",
    "        data.curve_samples = (\n",
    "            data.curve_samples.flip(dims=(1,)).T * part.edge_curve_flipped + \n",
    "            data.curve_samples.T * (1-part.edge_curve_flipped)\n",
    "        ).T.float()\n",
    "        \n",
    "        data.__node_sets__.add('surface_bounds')\n",
    "        data.__node_sets__.add('surface_coords')\n",
    "        data.__node_sets__.add('surface_samples')\n",
    "        data.__node_sets__.add('curve_bounds')\n",
    "        data.__node_sets__.add('curve_samples')\n",
    "\n",
    "        self.data = data\n",
    "    \n",
    "    def transform(self, translation, scale):\n",
    "        pass\n",
    "\n",
    "    def augment(self):\n",
    "        pass\n",
    "\n",
    "    def to_brep(self):\n",
    "        pass\n",
    "    \n",
    "#hp = HPart('../../datasets/cubes/angled_cube.x_t', normalize=True)\n",
    "#hp = HPart('../../datasets/frame_guide/fg1.x_t', n_samples=500, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part = HybridPart('../../caddata/frame_guide/fg1.x_t', 500, 5000, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = HPart('../../caddata/frame_guide/fg1.x_t',n_samples=500, normalize=True)#'../../datasets/frame_guide/fg1.x_t', n_samples=500, normalize=True)\n",
    "hpd = hp.data\n",
    "gt_u = hpd.surface_coords[11][:,0].detach().numpy()\n",
    "gt_v = hpd.surface_coords[11][:,1].detach().numpy()\n",
    "gt_mask = hpd.surface_samples[11][:,-1].detach().numpy()\n",
    "\n",
    "plt.scatter(gt_u,gt_v,c=gt_mask)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpx = HybridPart('../../datasets/cubes/angled_cube.x_t',500,5000,False)\n",
    "hps = HybridPart('../../datasets/cubes/angled_cube.step',500,5000,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate GCN Layers that support edge attributes and bipartite graphs\n",
    "# We would also love to have some form of residual here if possible\n",
    "from automate import BipartiteResMRConv\n",
    "from torch_geometric.nn import (\n",
    "    GATv2Conv, # Number of attention heads is likely important, lazy\n",
    "    TransformerConv, # Number of attention heads likely important, lazy, can do weighted residual\n",
    "    GINEConv, # No residual-like function\n",
    "    GMMConv, # Guassion-Mixture Model (2016), lazy\n",
    "    NNConv, # Provide your own NN as input, lazy\n",
    "    CGConv, # Used for crystal graphs\n",
    "    GENConv, # From follow-up to DeepGCNs - very general, and lazy\n",
    "    GeneralConv # From Design Space for GNNs paper, lazy, can do attention w/ multiple heads\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "if platform.system() == 'Linux' and 'microsoft' not in platform.release():\n",
    "    os.environ['PYOPENGL_PLATFORM'] = 'egl'\n",
    "import pyrender\n",
    "\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "from pytorch_lightning import LightningModule\n",
    "from hybridbrep import ImplicitDecoder\n",
    "\n",
    "class HybridPredictor(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.renderer = None\n",
    "\n",
    "    def ensure_renderer(self):\n",
    "        if self.renderer is None:\n",
    "            self.renderer = pyrender.OffscreenRenderer(\n",
    "                viewport_width=200,\n",
    "                viewport_height=200,\n",
    "                point_size=1.0\n",
    "            )\n",
    "        pass\n",
    "\n",
    "    def destroy_renderer(self):\n",
    "        if self.renderer is not None:\n",
    "            self.renderer.delete()\n",
    "\n",
    "    def forward(self, batch, face_coords, edge_coords=None):\n",
    "        return self.model(batch, face_coords, edge_coords)\n",
    "\n",
    "    def mesh_enc_dec(self, batch, n_samples, grid_bounds=(-.1,1.1)):\n",
    "        face_codes = self.encode_faces(batch)\n",
    "        edge_codes = self.encode_edges(batch)\n",
    "        Vs, Fs = self.mesh_decode(face_codes, n_samples, edge_codes, grid_bounds)\n",
    "        # TODO - label by originating part\n",
    "        return Vs, Fs\n",
    "\n",
    "    def mesh_decode(self, face_codes, n_samples=50, edge_codes=None, grid_bounds=(-.1,1.1)):\n",
    "        decoded = self.grid_decode(face_codes, n_samples, edge_codes, grid_bounds)\n",
    "        if edge_codes is None:\n",
    "            face_preds = decoded\n",
    "        else:\n",
    "            face_preds, edge_preds = decoded\n",
    "        Vs = None\n",
    "        Fs = None\n",
    "        # TODO - renumber by originating part if reasonable\n",
    "        return Vs, Fs\n",
    "\n",
    "    def grid_enc_dec(self, batch, n_samples=50, grid_bounds=(-.1,1.1)):\n",
    "        face_codes = self.encode_faces(batch)\n",
    "        edge_codes = self.encode_edges(batch)\n",
    "        return self.grid_decode(face_codes, n_samples, edge_codes, grid_bounds)\n",
    "    \n",
    "    def grid_decode(self, face_codes, n_samples=50, edge_codes=None, grid_bounds=(-.1,1.1)):\n",
    "        n_faces = face_codes.shape[0]\n",
    "        face_u = torch.linspace(0, 1, n_samples, device=face_codes.device)\n",
    "        face_uv = torch.stack([torch.cartesian_prod(face_u, face_u)]*n_faces)\n",
    "        #face_batch = torch.arange(n_faces).repeat_interleave(3)\n",
    "        face_preds = self.decode_faces(face_codes, face_uv)\n",
    "        if edge_codes is not None:\n",
    "            n_edges = edge_codes.shape[0]\n",
    "            edge_grid = torch.linspace(0.0,1.0,n_samples,device=edge_codes.device).repeat(n_edges,1)\n",
    "            edge_preds = self.decode_edges(edge_codes, edge_grid)\n",
    "            return face_preds, edge_preds\n",
    "        else:\n",
    "            return face_preds\n",
    "        \n",
    "        \n",
    "\n",
    "    def eval_common(self, batch, batch_idx):\n",
    "        # Edge Targets and coordinates\n",
    "        n_curves, n_c_samples, c_sample_dim = batch.curve_samples.shape\n",
    "        c_xyz = batch.curve_samples[:,:,:3].reshape((-1,3))\n",
    "        edge_coords = torch.linspace(0.,1.,n_c_samples,device=batch.faces.device).repeat(n_curves).reshape((n_curves,-1))\n",
    "\n",
    "        # Face Targets\n",
    "        n_surfs, n_s_samples, s_sample_dim = batch.surface_samples.shape\n",
    "        s_xyz = batch.surface_samples[:,:,:3].reshape((-1,3))\n",
    "        s_m = batch.surface_samples[:,:,s_sample_dim-1].flatten()\n",
    "        face_coords = batch.surface_coords\n",
    "\n",
    "        _, face_preds, _, edge_preds = self(batch, face_coords, edge_coords)\n",
    "\n",
    "        face_preds_xyz = face_preds[:,:3]\n",
    "        face_preds_m = face_preds[:,3]\n",
    "\n",
    "        edge_loss = torch.nn.functional.mse_loss(edge_preds, c_xyz)\n",
    "        face_loss_xyz = torch.nn.functional.mse_loss(face_preds_xyz, s_xyz)\n",
    "        face_loss_mask = ((face_preds_m - s_m)**2).mean()#torch.nn.functional.mse_loss(face_preds_m, s_m)\n",
    "\n",
    "        loss = edge_loss + face_loss_xyz + face_loss_mask\n",
    "\n",
    "        return loss, edge_loss, face_loss_xyz, face_loss_mask\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, edge_loss, face_loss_xyz, face_loss_mask = self.eval_common(batch, batch_idx)\n",
    "        self.log('edge_loss', edge_loss)\n",
    "        self.log('face_loss_xyz', face_loss_xyz)\n",
    "        self.log('face_loss_mask', face_loss_mask)\n",
    "        self.log('loss', loss)\n",
    "        return face_loss_mask\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=5e-4)\n",
    "\n",
    "class GeneralConvEncDec(HybridPredictor):\n",
    "    def __init__(self, emb_dim=128, dec_dim=128, dec_layers=4):\n",
    "        super().__init__()\n",
    "        self.edge_enc = GeneralConv(-1,emb_dim,-1, attention=True, heads=2)\n",
    "        self.face_enc = GeneralConv(-1,emb_dim,-1, attention=True, heads=8)\n",
    "        self.edge_dec = ImplicitDecoder(emb_dim+1, 3, dec_dim, dec_layers, use_tanh=False)\n",
    "        self.face_dec = ImplicitDecoder(emb_dim+2, 4, dec_dim, dec_layers, use_tanh=False)\n",
    "    \n",
    "    def encode_edges(self, batch):\n",
    "        oh= torch.nn.functional.one_hot(torch.arange(len(batch.edges), device=batch.faces.device)).float()\n",
    "        edge_codes = self.edge_enc((batch.vertices,batch.edges),batch.vertex_to_edge,None,batch.vertex_to_edge_is_start)\n",
    "        edge_codes = torch.zeros_like(edge_codes)\n",
    "        edge_codes[:,:oh.shape[1]] = oh\n",
    "        return edge_codes.float()\n",
    "\n",
    "    def encode_faces(self, batch, edge_codes=None):\n",
    "        if edge_codes is None:\n",
    "            edge_codes = self.encode_edges(batch)\n",
    "        oh = torch.nn.functional.one_hot(torch.arange(len(batch.faces),device=batch.faces.device)).float()\n",
    "        face_codes = self.face_enc((edge_codes, batch.faces),batch.edge_to_face,None,batch.edge_to_face_flipped)\n",
    "        face_codes = torch.zeros_like(face_codes)\n",
    "        face_codes[:,:oh.shape[1]] = oh\n",
    "        return face_codes\n",
    "\n",
    "    def decode_faces(self, face_codes, face_coords):\n",
    "        n_surfs, n_s_samples, _ = face_coords.shape\n",
    "        s_uv = face_coords.reshape((-1,2))\n",
    "        rep_face_codes = face_codes.repeat_interleave(n_s_samples,dim=0)\n",
    "        face_dec_input = torch.cat([s_uv, rep_face_codes],dim=1)\n",
    "        return self.face_dec(face_dec_input)\n",
    "\n",
    "    def enc_dec(self, batch, face_coords, edge_coords=None):\n",
    "        edge_codes = self.encode_edges(batch)\n",
    "        face_codes = self.encode_faces(batch, edge_codes)\n",
    "        face_preds = self.decode_faces(face_codes, face_coords)\n",
    "        if edge_coords is None:\n",
    "            return face_codes, face_preds\n",
    "        edge_preds = self.decode_edges(edge_codes, edge_coords)\n",
    "        return face_codes, face_preds, edge_codes, edge_preds\n",
    "\n",
    "    # edge_coords: [n_edges x n_edge_samples]\n",
    "    def decode_edges(self, edge_codes, edge_coords):\n",
    "        n_edges, n_c_samples = edge_coords.shape\n",
    "        c_t = edge_coords.reshape((-1,1))\n",
    "        rep_face_codes = edge_codes.repeat_interleave(n_c_samples,dim=0)\n",
    "        face_dec_input = torch.cat([c_t, rep_face_codes],dim=1)\n",
    "        return self.edge_dec(face_dec_input)\n",
    "\n",
    "    def forward(self, batch, face_coords, edge_coords=None):\n",
    "        return self.enc_dec(batch, face_coords, edge_coords)\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "hp = HPart('../../caddata/frame_guide/fg1.x_t',n_samples=2000, normalize=True)#'../../datasets/frame_guide/fg1.x_t', n_samples=500, normalize=True)\n",
    "class FixedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = hp.data\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "\n",
    "num_epochs = 500\n",
    "dl = tg.loader.DataLoader(FixedDataset(), batch_size=1)\n",
    "model = GeneralConvEncDec(emb_dim=64, dec_dim=1024, dec_layers=4)\n",
    "model = model.to('cuda')\n",
    "dat = next(iter(dl))\n",
    "dat = dat.to('cuda')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "losses=[]\n",
    "optimizer = model.configure_optimizers()\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    optimizer.zero_grad()\n",
    "    loss = model.training_step(dat, 0)\n",
    "    loss.backward()\n",
    "    losses.append(loss.detach().to('cpu').item())\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    #model.load_state_dict(sd)\n",
    "    #print(model.eval_common(next(iter(dl)),0))\n",
    "    #trainer = pl.Trainer(max_epochs=num_epochs,log_every_n_steps=1)\n",
    "    #trainer.fit(model,dl)\n",
    "    #print(model.eval_common(next(iter(dl)),0))\n",
    "\n",
    "    #model = model.to('cpu')\n",
    "\n",
    "    #batch = next(iter(dl))\n",
    "    n_curves, n_c_samples, c_sample_dim = dat.curve_samples.shape\n",
    "    #c_xyz = batch.curve_samples[:,:,:3].reshape((-1,3))\n",
    "    edge_coords = torch.linspace(0.,1.,n_c_samples,device=dat.curve_samples.device).repeat(n_curves).reshape((n_curves,-1))\n",
    "\n",
    "    # Face Targets\n",
    "    #n_surfs, n_s_samples, s_sample_dim = batch.surface_samples.shape\n",
    "    #s_xyz = batch.surface_samples[:,:,:3].reshape((-1,3))\n",
    "    #s_m = batch.surface_samples[:,:,s_sample_dim-1].flatten()\n",
    "    #face_coords = batch.surface_coords\n",
    "\n",
    "    #fc,fp,ec,ep = model(batch, face_coords, edge_coords)\n",
    "    grid_size = 75\n",
    "    fp, ep = model.grid_enc_dec(dat,grid_size)\n",
    "    fp = fp.to('cpu')\n",
    "    ep = ep.to('cpu')\n",
    "\n",
    "    _,fp_batch,_,ep_batch = model(dat, dat.surface_coords, edge_coords)\n",
    "    fp_batch = fp_batch.to('cpu')\n",
    "    ep_batch = ep_batch.to('cpu')\n",
    "    del edge_coords\n",
    "    #V = batch.curve_samples[:,:,:3].reshape((-1,3)).numpy()\n",
    "    #plot = mp.plot(ep.detach().numpy(), return_plot=True, shading={'point_size':0.3})\n",
    "    #plot.add_points(V, shading={'point_color':'green', 'point_size':0.3})\n",
    "    #points = fp[:,:3]\n",
    "    mask = fp[:,3].reshape((-1,grid_size,grid_size)).flip(dims=(2,)).numpy()\n",
    "    mask_batch = fp_batch[:,-1].numpy().reshape((dat.surface_coords.shape[0],-1))\n",
    "    uv_batch = dat.surface_coords.to('cpu').numpy()\n",
    "\n",
    "    #m_points = points[mask <= 0]\n",
    "    plt.plot(losses)\n",
    "    plt.title('Losses')\n",
    "    plt.figure()\n",
    "    plt.imshow(mask[11].T)\n",
    "    plt.title('Grid Prediction')\n",
    "    plt.colorbar()\n",
    "    plt.figure()\n",
    "    plt.imshow(mask[11].T <= 0)\n",
    "    plt.title('Grid Prediction Mask')\n",
    "    plt.colorbar()\n",
    "    plt.figure()\n",
    "    plt.scatter(uv_batch[11,:,0],uv_batch[11,:,1],c=mask_batch[11])\n",
    "    plt.title('Point Prediction')\n",
    "    plt.colorbar()\n",
    "    plt.figure()\n",
    "    plt.scatter(uv_batch[11,:,0],uv_batch[11,:,1],c=dat.surface_samples[11,:,-1].to('cpu').numpy())\n",
    "    plt.title('Point Ground Truth')\n",
    "    plt.colorbar()\n",
    "    plt.figure()\n",
    "    plt.scatter(uv_batch[11,:,0],uv_batch[11,:,1],c=np.abs((dat.surface_samples[11,:,-1].to('cpu').numpy()-mask_batch[11])))\n",
    "    plt.title('Point Residual')\n",
    "    plt.colorbar()\n",
    "\n",
    "    del dat\n",
    "    del model\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "#plot.add_points(points.detach().numpy(), c=(mask.detach().numpy() <= 0), shading={'point_color':'blue', 'point_size':0.15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask[11].T <= 0.03)\n",
    "plt.title('Grid Prediction')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.faces.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del fp_batch, ep_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fc,fp,ec,ep = model(batch, face_coords, edge_coords)\n",
    "\n",
    "gp = model.grid_enc_dec(next(iter(dl)),50)\n",
    "fp,ep = gp\n",
    "V = batch.curve_samples[:,:,:3].reshape((-1,3)).numpy()\n",
    "#plot = mp.plot(ep.detach().numpy(), return_plot=True, shading={'point_size':0.3})\n",
    "#plot.add_points(V, shading={'point_color':'green', 'point_size':0.3})\n",
    "points = fp[:,:3]\n",
    "mask = fp[:,3]\n",
    "m_points = points[mask <= 0]\n",
    "plt.imshow((mask.reshape((-1,50,50)) <= 0)[11].detach().numpy())\n",
    "#plot.add_points(points.detach().numpy(), c=(mask.detach().numpy() <= 0), shading={'point_color':'blue', 'point_size':0.15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc,fp,ec,ep = model(batch, face_coords, edge_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current problems are _both_ not enough sample density and not enough\n",
    "# predictor resolution\n",
    "# Proposed Solutions:\n",
    "# - sample density - preferentially sample near boundaries\n",
    "# - prediction resolution - try a siren-net or similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.surface_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mask = fp.reshape((-1,1000,4))[11][:,-1].detach().numpy()\n",
    "plt.scatter(gt_u,gt_v,c=pred_mask)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = HPart('../../caddata/frame_guide/fg1.x_t',n_samples=1000, normalize=True).data#'../../datasets/frame_guide/fg1.x_t', n_samples=500, normalize=True)\n",
    "\n",
    "gt_u = hp.surface_coords[11][:,0].detach().numpy()\n",
    "gt_v = hp.surface_coords[11][:,1].detach().numpy()\n",
    "gt_mask = hp.surface_samples[11][:,-1].detach().numpy()\n",
    "\n",
    "plt.scatter(gt_u,gt_v,c=gt_mask)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_mask.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = batch.surface_samples[11,:,:3].reshape((-1,3))\n",
    "mask = batch.surface_samples[11,:,-1].flatten()\n",
    "V_m = V[mask <= 0].detach().numpy()\n",
    "mp.plot(V.detach().numpy(),c=(mask.detach().numpy()<=0),shading={'point_size':0.4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(gt_u, gt_v,c=gt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = model.grid_enc_dec(next(iter(dl)),50)\n",
    "fp,ep = gp\n",
    "V = batch.curve_samples[:,:,:3].reshape((-1,3)).numpy()\n",
    "plot = mp.plot(ep.detach().numpy(), return_plot=True, shading={'point_size':0.3})\n",
    "plot.add_points(V, shading={'point_color':'green', 'point_size':0.3})\n",
    "points = fp[:,:3]\n",
    "mask = fp[:,3]\n",
    "plot.add_points(points.detach().numpy(), c=(mask.detach().numpy() <= 0), shading={'point_color':'blue', 'point_size':0.15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = mp.plot(ep.detach().numpy(), return_plot=True)\n",
    "plot.add_points(V, shading={'point_color':'green'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp[:,:3].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp[:,:3].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.surface_samples[:,:,:3].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gp = model.grid_enc_dec(next(iter(dl)),23)\n",
    "#fp,ep = gp\n",
    "fc,fp,ec,ep = model(batch, face_coords, edge_coords)\n",
    "\n",
    "V = batch.curve_samples[:,:,:3].reshape((-1,3)).numpy()\n",
    "V_f = batch.surface_samples[:,:,:3].reshape((-1,3)).numpy()\n",
    "V_f = V_f[(batch.surface_samples[:,:,-1] <= 0).flatten().numpy()]\n",
    "plot = mp.plot(ep.detach().numpy(), return_plot=True, shading={'point_size':0.3})\n",
    "plot.add_points(V, shading={'point_color':'green', 'point_size':0.3})\n",
    "plot.add_points(V_f, shading={'point_color':'blue', 'point_size':0.15})\n",
    "#plot.add_points(fp[:,:3].detach().numpy(), shading={'point_color':'blue', 'point_size':0.15})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.surface_samples[:,:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (d->h)*1, (d+h->h)*K, (d+h->o)*1\n",
    "\n",
    "# ([dxh],[h]),  ([d+hxh],[h])*K, ([d+h x o], [o])\n",
    "\n",
    "dim=1\n",
    "hidden_dim=64\n",
    "hidden_layers=4\n",
    "out = 4\n",
    "\n",
    "def lin_size(in_size, out_size):\n",
    "    return in_size*out_size + out_size\n",
    "\n",
    "def make_linear_layer(embedding, shape):\n",
    "    (in_size, out_size) = shape\n",
    "    weights = embedding[:in_size*out_size].reshape((in_size, out_size))\n",
    "    biases = embedding[in_size*out_size,in_size*out_size+out_size]\n",
    "    rest = embedding[in_size*out_size+out_size:]\n",
    "    return (weights, biases, rest)\n",
    "\n",
    "emb_size = (\n",
    "    (dim*hidden_dim) + hidden_dim + # Input layer\n",
    "    ( (dim+hidden_dim)*hidden_dim + hidden_dim)*(hidden_layers-1) + # Hidden Layers\n",
    "    (dim+hidden_dim)*out + out # Output Layers\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19a52af1d545bce9f2ee66b8002db2e069279244d5f15bea3b84d7219dd7585f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
